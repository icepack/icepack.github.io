
.. code:: ipython3

    %matplotlib inline
    import os
    import matplotlib.pyplot as plt
    import numpy as np
    import rasterio
    import geojson
    import firedrake
    import icepack, icepack.plot, icepack.models

Larsen Ice Shelf
================

This demo will involve using real data for the Larsen Ice Shelf in the
Antarctic Peninsula. The use of real data will mostly change how we set
up the simulation. The simulation itself â€“ involving successive
prognostic and diagnostic solves of the physics model â€“ is virtually
identical to what we saw in the last demo.

To access the data weâ€™ll use, youâ€™ll need to have a login for
`EarthData <https://urs.earthdata.nasa.gov/>`__, the web portal through
which NASA makes remote sensing data available to the public. Most of
the ice sheet remote sensing data produced by American research
institutions is hosted at the `National Snow and Ice Data Center
(NSIDC) <https://www.nsidc.org>`__ and an EarthData login is necessary
to access data from NSIDC.

The external data that we will use are: \* a velocity map of Antarctica
produced as part of the MEaSUREs program, which you can read more about
`here <https://nsidc.org/data/nsidc-0484>`__ \* an ice thickness map
from the `bedmap2 <https://www.bas.ac.uk/project/bedmap-2/>`__ data set,
which is available from the British Antarctic Survey \* an outline of
the Larsen C Ice Shelf that I created by tracing over satellite imagery
in a `geographic information
system <https://en.wikipedia.org/wiki/Geographic_information_system>`__.

Rather than manually download these data sets from the websites theyâ€™re
hosted on, weâ€™ll call a few functions in the module ``data.py`` in this
directory to fetch them for us. (Internally, these functions use a
library called `pooch <https://github.com/fatiando/pooch>`__ which
handles things like caching the data so it doesnâ€™t get downloaded twice,
unzipping archived files, and so forth.) One we have the gridded data
sets weâ€™ll use the library
`rasterio <https://rasterio.readthedocs.io/en/stable/>`__ to read them.
Both pooch and rasterio will have been installed along with icepack, so
you donâ€™t need to do this yourself.

Geometry
~~~~~~~~

First, weâ€™ll fetch a `GeoJSON <https://en.wikipedia.org/wiki/GeoJSON>`__
file describing the outline of the domain. GeoJSON is a common file
format for geospatial vector data. In the previous demo, we generated a
.geo file describing the outline of the domain, and then called gmsh to
create a triangulation of the interior. For this demo, weâ€™ll use a
different helper script that will turn our .geojson file into the .geo
format that gmsh expects.

To retrieve the external data, weâ€™ll use several functions in the module
``data.py``. All of these functions start with ``fetch``. These
functions retrieve the external data from the internet and put them in a
predictable location so they can be found easily later. The files will
be will only be downloaded the first time you fetch them; this caching
functionality will come in handy because weâ€™ll be using much of the same
data in later demos.

.. code:: ipython3

    import data
    outline_filename = data.fetch_larsen_outline()
    print(outline_filename)


.. parsed-literal::

    /home/daniel/.cache/icepack/larsen.geojson


To read this file weâ€™ll use the GeoJSON package. We wonâ€™t go into a
great amount of detail about analyzing geospatial vector data here, but
a few basic features are worth going over.

.. code:: ipython3

    with open(outline_filename, 'r') as outline_file:
        outline = geojson.load(outline_file)

From the userâ€™s perspective, a GeoJSON object looks like a big nested
dictionary, and somewhere down the line are some arrays of coordinates.
Here weâ€™ll access the `coordinate reference system
(CRS) <https://en.wikipedia.org/wiki/Spatial_reference_system>`__ that
the data are stored in. The most common reference systems are
standardized and given numeric ID codes by some standards body, in this
case the European Petroleum Survey Group (EPSG). The most common CRS for
Antarctic data sets is EPSG:3031, which is a polar stereographic
projection centered on the South Pole.

.. code:: ipython3

    print(outline['crs']['properties']['name'])


.. parsed-literal::

    urn:ogc:def:crs:EPSG::3031


For good measure weâ€™ll read every feature in the outline and plot the
coordinates.

.. code:: ipython3

    fig, axes = icepack.plot.subplots()
    
    for feature in outline['features']:
        for line_string in feature['geometry']['coordinates']:
            xs = np.array(line_string)
            axes.plot(xs[:, 0], xs[:, 1])
            
    axes.set_xlabel('meters')
    plt.show(fig)



.. image:: icepack.demo.02-larsen-ice-shelf_files/icepack.demo.02-larsen-ice-shelf_9_0.png


Next weâ€™ll take this GeoJSON object and translate it into a geometry
object from pygmsh. The function to do that is contained in the module
``meshing.py``. We can then save this to a .geo file and run gmsh on the
result, just like we did in the previous demo.

.. code:: ipython3

    import meshing
    geometry = meshing.collection_to_geo(outline)

.. code:: ipython3

    with open('larsen.geo', 'w') as geo_file:
        geo_file.write(geometry.get_code())

The call to gmsh is the same as in the previous demo, but weâ€™ll make the
output less verbose by passing the flag ``-v 2`` as well.

.. code:: ipython3

    !gmsh -2 -format msh2 -v 2 -o larsen.msh larsen.geo

Now that weâ€™ve generated the mesh we can read it just like we did in the
previous demo.

.. code:: ipython3

    mesh = firedrake.Mesh('larsen.msh')

Finally weâ€™ll make a plot of the mesh so that we can see all the
boundary IDs. Boundary segments 1 and 3 correspond to the calving
terminus and these are where Neumann boundary conditions should be
applied. Segment 2 borders the Gipps Ice Rise, and the remaining
segments are where ice is flowing in from.

.. code:: ipython3

    fig, axes = icepack.plot.subplots()
    axes.grid()
    axes.set_xlabel('meters')
    icepack.plot.triplot(mesh, axes=axes, linewidth=1)
    plt.show(fig)



.. image:: icepack.demo.02-larsen-ice-shelf_files/icepack.demo.02-larsen-ice-shelf_18_0.png


Input data
~~~~~~~~~~

Next, we have to load the input data, starting with the ice thickness.
The bedmap2 dataset that we use actually includes several fields â€“
thickness, surface elevation, bed elevation, an ice shelf and rock mask,
etc. The function ``fetch_bedmap2`` will download the dataset from the
internet, unzip it, and return a list of the paths of all the files it
retrieved rather than just a single file like the ``fetch_larsen_mesh``
function did.

.. code:: ipython3

    bedmap2_files = data.fetch_bedmap2()
    for filename in bedmap2_files:
        print(filename)


.. parsed-literal::

    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/bedmap2_thickness.tif
    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/bedmap2_icemask_grounded_and_shelves.tif
    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/bedmap2_lakemask_vostok.tif
    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/bedmap2_coverage.tif
    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/bedmap2_grounded_bed_uncertainty.tif
    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/bedmap2_bed.tif
    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/bedmap2_surface.tif
    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/gl04c_geiod_to_WGS84.tif
    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/bedmap2_rockmask.tif
    /home/daniel/.cache/icepack/bedmap2_tiff.zip.unzip/bedmap2_tiff/bedmap2_thickness_uncertainty_5km.tif


Weâ€™re only interested in the thickness data itself, so the following
command will pull it out from the list of all the other files in the
bedmap2 dataset.

.. code:: ipython3

    thickness_filename = [f for f in bedmap2_files if
                          os.path.basename(f) == 'bedmap2_thickness.tif'][0]

The thickness data are stored in a
`GeoTIFF <https://en.wikipedia.org/wiki/GeoTIFF>`__ file. GeoTIFF is a
common storage format for geospatial data; it adds georeferencing
information on top of the TIFF file format, which is often used for
lossless compression of images. The function ``rasterio.open`` will give
us an object representing the raster data set that we can then read
from.

.. code:: ipython3

    thickness = rasterio.open(thickness_filename, 'r')

Opening the file doesnâ€™t immediately read all the data at once. Instead,
that occurs through calls to the ``read`` method of the data set, in our
case the variable ``thickness``. The actual reading will occur entirely
within the functions that interpolate the raster data to our
computational mesh. This two-step procedure involves a little extra
code, but the nice part is that you can read only as small a chunk of
the data as need be. It would be awfully wasteful if you had to load up
the thickness of all of Antarctica only to focus on a little piece like
the Larsen Ice Shelf.

Before going on, letâ€™s make a plot of the thickness data. Plotting all
your data first is a good sanity check to make sure that it isnâ€™t, say,
stored upside-down, or in a different coordinate system than you
expected. To visualize our data, weâ€™ll use the function ``contourf`` in
the module ``icepack.plot``, which works just like the equivalent
matplotlib function.

.. code:: ipython3

    fig, axes = icepack.plot.subplots()
    contours = icepack.plot.contourf(thickness, 40, axes=axes)
    fig.colorbar(contours, label='meters')
    plt.show(fig)



.. image:: icepack.demo.02-larsen-ice-shelf_files/icepack.demo.02-larsen-ice-shelf_27_0.png


Next, we have to fetch the velocity data, which are hosted on NSIDC. The
following will prompt for your EarthData login if need be. The file is
~6GiB, so if you run this demo yourself, this step could take a while.

.. code:: ipython3

    velocity_filename = data.fetch_measures_antarctica()

The velocity data are stored in a
`NetCDF <https://en.wikipedia.org/wiki/NetCDF>`__ file. NetCDF is
another common storage format for geophysical data, especially in
atmospheric science. NetCDF offers much more freedom than GeoTIFF in
terms of what kind of data can be stored, so you have to know something
about the schema or layout before you use it. For example, many fields
can be stored by name in a NetCDF file, and you have to know what all
the names are. The script ``ncinfo`` will print out information about
all the fields stored in a NetCDF file.

.. code:: ipython3

    !ncinfo "$velocity_filename"


.. parsed-literal::

    <class 'netCDF4._netCDF4.Dataset'>
    root group (NETCDF4 data model, file format HDF5):
        Conventions: CF-1.6
        Metadata_Conventions: CF-1.6, Unidata Dataset Discovery v1.0, GDS v2.0
        standard_name_vocabulary: CF Standard Name Table (v22, 12 February 2013)
        id: vel_nsidc.CF16.nc
        title: MEaSURES Antarctica Ice Velocity Map 450m spacing
        product_version:  
        summary:  
        keywords:  
        keywords_vocabulary:  
        platform:  
        sensor:  
        date_created: 2017-04-06T17:47:44.00004923343322Z
        institution: Department of Earth System Science, University of California, Irvine
        cdm_data_type: Grid
        geospatial_lat_units: degrees_north
        geospatial_lon_units: degrees_east
        geospatial_lat_min: -90
        geospatial_lat_max: -60
        geospatial_lon_min: -180
        geospatial_lon_max: 180
        spatial_resolution: 450m
        time_coverage_start: 1995-01-01
        time_coverage_end: 2016-12-31
        project: NASA/MEaSUREs
        creator_name: J. Mouginot
        license: No restrictions on access or use
        dimensions(sizes): x(12445), y(12445)
        variables(dimensions): |S1 [4mcoord_system[0m(), float64 [4mx[0m(x), float64 [4my[0m(y), float64 [4mlat[0m(y,x), float64 [4mlon[0m(y,x), float32 [4mVX[0m(y,x), float32 [4mVY[0m(y,x), float32 [4mSTDX[0m(y,x), float32 [4mSTDY[0m(y,x), float32 [4mERRX[0m(y,x), float32 [4mERRY[0m(y,x), int32 [4mCNT[0m(y,x)
        groups: 
    


The fields we want are ``VX`` and ``VY``. We can use rasterio can read
NetCDF files too, but we have to add in a bit of extra magic so itâ€™ll
know that we want to get the ``VX`` and ``VY``. To specify which field
weâ€™re reading, we can prepend ``netcdf:`` to the beginning of the
filename and append ``:FIELD_NAME`` to the string we pass to
``rasterio.open``.

.. code:: ipython3

    vx = rasterio.open('netcdf:' + velocity_filename + ':VX', 'r')
    vy = rasterio.open('netcdf:' + velocity_filename + ':VY', 'r')

Modeling
~~~~~~~~

Having done all the leg work to make a mesh and get a good set of input
data, the modeling itself should be fairly familiar from the last step.
Weâ€™ll assume that the ice temperature is a uniform :math:`-13^\circ`\ C.

One thing is substantially different from previous examples. Before, we
called the function ``firedrake.SpatialCoordinate`` to get some symbolic
handles ``x, y`` for the mesh coordinates, and we created symbolic
expressions to define the input data to our problem analytically. When
we work with real data, we instead use icepackâ€™s ``GridData`` object,
which firedrake doesnâ€™t know how to interpolate. The function
``icepack.interpolate`` works as a layer on top of the firedrake
interpolate function and knows what to do with gridded data sets.

.. code:: ipython3

    degree = 2
    Q = firedrake.FunctionSpace(mesh, family='CG', degree=degree)
    V = firedrake.VectorFunctionSpace(mesh, family='CG', degree=degree)
    
    h0 = icepack.interpolate(thickness, Q)
    u0 = icepack.interpolate((vx, vy), V)

.. code:: ipython3

    fig, axes = icepack.plot.subplots()
    streamlines = icepack.plot.streamplot(u0, precision=1000, density=2500, axes=axes)
    fig.colorbar(streamlines, label='meters/year')
    plt.show(fig)



.. image:: icepack.demo.02-larsen-ice-shelf_files/icepack.demo.02-larsen-ice-shelf_36_0.png


.. code:: ipython3

    T = 260
    A = firedrake.interpolate(firedrake.Constant(icepack.rate_factor(T)), Q)
    
    ice_shelf = icepack.models.IceShelf()
    opts = {'dirichlet_ids': [2, 4, 5, 6, 7, 8], 'tol': 1e-6}
    u = ice_shelf.diagnostic_solve(u0=u0, h=h0, A=A, **opts)

.. code:: ipython3

    fig, axes = icepack.plot.subplots()
    streamlines = icepack.plot.streamplot(u, precision=1000, density=2500, axes=axes)
    fig.colorbar(streamlines, label='meters/year')
    plt.show(fig)



.. image:: icepack.demo.02-larsen-ice-shelf_files/icepack.demo.02-larsen-ice-shelf_38_0.png


We get a fairly reasonable approximation for the velocity even with a
spatially homogeneous guess for the ice temperature.

.. code:: ipython3

    print(icepack.norm(u - u0) / icepack.norm(u0))


.. parsed-literal::

    0.1148285049798471


Ballpark estimate, the surface and basal mass balance of Larsen C are
+30 and -30 cm/yr respectively, so we can take the total to be 0. Letâ€™s
simulate the evolution of the ice shelf for the next 10 years. The code
for this loop should be familiar from the previous example.

.. code:: ipython3

    a = firedrake.Function(Q)
    h = h0.copy(deepcopy=True)
    
    dt = 0.5
    for n in range(int(10 / dt) + 1):
        h = ice_shelf.prognostic_solve(dt, h0=h, a=a, u=u, h_inflow=h0)
        u = ice_shelf.diagnostic_solve(u0=u, h=h, A=A, **opts)

.. code:: ipython3

    fig, axes = icepack.plot.subplots()
    contours = icepack.plot.tricontourf(h, 96, axes=axes)
    fig.colorbar(contours, label='meters')
    plt.show(fig)



.. image:: icepack.demo.02-larsen-ice-shelf_files/icepack.demo.02-larsen-ice-shelf_43_0.png


By plotting the difference between the modeled thickness after 10 years
and the initial thickness, we can see the propagation of the rifts
downstream. This effect is best visualized with a diverging colormap
that makes the 0-contour really obvious.

.. code:: ipython3

    Î´h = firedrake.Function(Q)
    Î´h.assign(h - h0)
    
    fig, axes = icepack.plot.subplots()
    contours = icepack.plot.tricontourf(Î´h, axes=axes, cmap='RdBu',
                                        levels=np.linspace(-10, +10, 101), extend='both')
    fig.colorbar(contours, label='meters')
    plt.show(fig)



.. image:: icepack.demo.02-larsen-ice-shelf_files/icepack.demo.02-larsen-ice-shelf_45_0.png


The oscillatory pattern makes it less than obvious whether the ice shelf
gained or lost mass, so letâ€™s evaluate the integral of the thickness
change to see.

.. code:: ipython3

    from firedrake import assemble, dx
    print(assemble(Î´h * dx) / assemble(1 * dx(mesh)))


.. parsed-literal::

    -3.781448124076765


Seeing as the simulation ran for 10 years, this isnâ€™t a wildly
unrealistic number.

Conclusion
~~~~~~~~~~

In the last demo, we showed how to simulate ice shelf flow using
synthetic data. Here we showed how to load in a generated mesh and
observational data, and we used this same functionality to simulate a
real ice shelf.

Many real data sets require some amount of preprocessing before they can
be used for modeling. For example, many velocity data sets have missing
pixels or patches due to noise in the optical or radar imagery, and
these missing points have to be filled in somehow. The Bedmap2 thickness
also contains processing artifacts that are visible as depressions
running diagonally across the ice shelf. These artifacts could be
removed by using a low-pass filter on the gridded data, although this
might also wash out some real features like the many rifts in the ice.

In order to run the simulation, we had to come up with a guess for the
ice rheology. The simple choice we made is quite far from the real value
and in a subsequent demo weâ€™ll show how to estimate it from
observational data.
